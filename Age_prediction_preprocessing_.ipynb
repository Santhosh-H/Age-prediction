{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF258wz2DqWq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, BatchNormalization, Flatten, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to the UTKFace dataset\n",
        "path = \"UTKFace/UTKFace\"\n",
        "\n",
        "# Initialize lists to store images, ages, and genders\n",
        "images = []\n",
        "ages = []\n",
        "genders = []\n",
        "\n",
        "# Load images and extract age and gender labels from filenames\n",
        "for img_name in os.listdir(path):\n",
        "    age = img_name.split(\"_\")[0]\n",
        "    gender = img_name.split(\"_\")[1]\n",
        "\n",
        "    # Read the image\n",
        "    img = cv2.imread(os.path.join(path, img_name))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Append the data to respective lists\n",
        "    images.append(img)\n",
        "    ages.append(int(age))  # Convert age to integer\n",
        "    genders.append(int(gender))  # Convert gender to integer\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "ages = np.array(ages, dtype=np.int64)\n",
        "genders = np.array(genders, dtype=np.uint64)\n",
        "images = np.array(images)\n",
        "\n",
        "# Resize images to 224x224 (ResNet input size)\n",
        "images_resized = np.array([cv2.resize(img, (224, 224)) for img in images])\n",
        "\n",
        "# Normalize images (ResNet expects images normalized to [-1, 1])\n",
        "images_normalized = images_resized / 127.5 - 1.0\n",
        "\n",
        "# Split the dataset for age prediction\n",
        "x_train_age, x_test_age, y_train_age, y_test_age = train_test_split(images_normalized, ages, random_state=42)\n",
        "\n",
        "# Split the dataset for gender prediction\n",
        "x_train_gender, x_test_gender, y_train_gender, y_test_gender = train_test_split(images_normalized, genders, random_state=42)\n",
        "\n",
        "print(\"Data preprocessing completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of Changes:\n",
        "Variable Names:\n",
        "\n",
        "Changed age to ages and gender to genders to avoid conflicts with loop variables.\n",
        "Resizing and Normalization:\n",
        "\n",
        "Added resizing of images to 224x224.\n",
        "Added normalization of images to the range [-1, 1].\n",
        "Updated Data Splits:\n",
        "\n",
        "The train_test_split function now operates on the resized and normalized images (images_normalized)."
      ],
      "metadata": {
        "id": "k_qIs1mBEWR4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lf0Or5yeEUjl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}